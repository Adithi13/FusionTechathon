# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jd-Ktk1z49bkGzSoc8GSH70UdCvcnj9Q
"""

!pip install nltk

import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

nltk.download('punkt')
nltk.download('stopwords')

# Define some greetings and responses
greetings = ['hello', 'hi', 'hey', 'howdy']
responses = ['Hello!', 'Hi there!', 'Hey!', 'How can I help you?']

# Tokenize the greetings and remove stopwords
def process_input(user_input):
    tokens = word_tokenize(user_input.lower())
    filtered_tokens = [word for word in tokens if word not in stopwords.words('english')]
    return filtered_tokens

# Generate a response based on user input
def generate_response(user_input):
    user_tokens = process_input(user_input)
    for token in user_tokens:
        if token in greetings:
            return responses[greetings.index(token)]
    return "I'm sorry, I don't understand that."

# Main loop
while True:
    user_input = input("You: ")
    if user_input.lower() == 'exit':
        print("Chatbot: Goodbye!")
        break
    response = generate_response(user_input)
    print("Chatbot:", response)

"""# ------------------------------------chatbot with the csv file---------------------------------"""

!pip install transformers

"""---------------------------------Ist part-------------------------------"""

import nltk
import csv
import torch
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from transformers import GPT2LMHeadModel, GPT2Tokenizer

nltk.download('punkt')
nltk.download('stopwords')

csv_file_path = '/content/d1.csv'


symptoms_dict = {}


with open(csv_file_path, 'r', encoding='utf-8') as csvfile:
    reader = csv.DictReader(csvfile)
    for row in reader:
        symptom = row['Symptoms'].lower()
        disease = row['diseases']
        treatment = row['treatments']
        prevention = row['preventive strategies']
        symptoms_dict[symptom] = {
            'disease': disease,
            'treatment': treatment,
            'prevention': prevention
        }


model_name = "gpt2"
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
model = GPT2LMHeadModel.from_pretrained(model_name)


def process_input(user_input):
    tokens = word_tokenize(user_input.lower())
    filtered_tokens = [word for word in tokens if word not in stopwords.words('english')]
    return filtered_tokens

def generate_response(user_input):
    user_tokens = process_input(user_input)
    for token in user_tokens:
        if token in symptoms_dict:
            disease_info = symptoms_dict[token]
            response = f"You might have {disease_info['disease']}. Here are some recommendations for you:\n"
            response += f"Treatment: {disease_info['treatment']}\n"
            response += f"Prevention: {disease_info['prevention']}"
            return response
    return "I'm sorry, I don't have information on that symptom."

while True:
    user_input = input("You: ")
    if user_input.lower() == 'exit':
        print("Chatbot: Goodbye!")
        break
    response = generate_response(user_input)

    input_ids = tokenizer.encode(response, return_tensors="pt")
    output = model.generate(input_ids, max_length=100, num_return_sequences=1, no_repeat_ngram_size=2)
    chatbot_response = tokenizer.decode(output[0], skip_special_tokens=True)

    print("Chatbot:", chatbot_response)

"""-------------------------------2nd part-----------------------------------"""

def process_input(user_input):
    tokens = word_tokenize(user_input.lower())
    filtered_tokens = [word for word in tokens if word not in stopwords.words('english')]
    return filtered_tokens

def generate_response(user_input):
    user_tokens = process_input(user_input)
    for token in user_tokens:
        if token in symptoms_dict:
            disease_info = symptoms_dict[token]
            response = f"You might have {disease_info['disease']}. Here are some recommendations for you:\n"
            response += f"Treatment: {disease_info['treatment']}\n"
            response += f"Prevention: {disease_info['prevention']}"
            return response
    return "I'm sorry, I don't have information on that symptom."

while True:
    user_input = input("You: ")
    if user_input.lower() == 'exit':
        print("Chatbot: Goodbye!")
        break
    response = generate_response(user_input)

    input_ids = tokenizer.encode(response, return_tensors="pt")
    output = model.generate(input_ids, max_length=100, num_return_sequences=1, no_repeat_ngram_size=2)
    chatbot_response = tokenizer.decode(output[0], skip_special_tokens=True)

    print("Chatbot:", chatbot_response)